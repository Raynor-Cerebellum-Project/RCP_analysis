# Analysis Pipeline for the Raynor Project

## Overview
This repository contains the analysis pipeline for preprocessing, quantifying, and comparing stimulation trials from the Raynor experiments.  

The workflow supports:
- Preprocessing of kinematics (Frame correction, alignment between cameras and to Blackrock (BR))
- Preprocessing Neuropixel read/write probe (NPRW) neural data
- Aligning BR recordings to Intan recordings
- Preprocessing Utah Array (UA) neural data
- Creating aligned .npz files TODO: switch to hdf5
- Combining baseline conditions for an aggregated baseline
- Visualization plots (Kinematics, NPRW, UA)


- TODO: Calculation of behavioral metrics TODO: Convert from MATLAB
- TODO: Artifact correction using template subtraction of stimulation artifacts

[Summary of recorded signals](https://docs.google.com/document/d/1C4-xSWL8n7P_mMrYqlUxQR6blz9WIHDU4B7O9bxhMnE/edit?tab=t.0)

[Example final figures: Bert's plots for headturn](https://docs.google.com/presentation/d/1z6fLBiO8Wbell_FSsJK0Mcj66stKMJZmZtJu6tcY7FA/edit?slide=id.g35fb40ee04d_0_42#slide=id.g35fb40ee04d_0_42)

The folder structure is as follows:
```
.
├── batch_scripts            # Batch scripts after finalizing from scripts
├── config                   # Config files
│   ├── params.yaml          # Params file indicating location of data and session
├── curation_scripts         # Curation includes visualizing kinematics and OCR frame correction
├── RCP_analysis             # Trained models
│   ├── MATLAB               # Unorganized MATLAB code
│   └── python               # Python code
│       ├── functions           # Functions for scripts
│       └── plotting            # Plotting code
├── scripts                  # Scripts for running batch scripts and plotting
├── LICENSE
└── README.md
```
Outputs:
```
.
├── data                         # Experimental data files as specified in params.yaml
│   ├── results                  # Output files generated by each code
│   │   ├── bundles              # Auxillary data other than neural data in .npz format (sync pulses etc.)
│   │   ├── checkpoints          # Intermediary files
│   │   └── figures              # Output figures
```
data and results (output) can be chosen to be other directories in config.


---

# Installing the pipeline


```bash
*navigate to desired directory*
# 1) clone repo
git clone https://github.com/Raynor-Cerebellum-Project/RCP_analysis.git
cd RCP_analysis

# 2) create env from environment.yml CHECK IF WE NEED ALL THESE PACKAGES
conda env create -f environment.yml -n pipeline python=3.10

# 3) install package and requirements
conda activate pipeline
python -m pip install --upgrade pip
pip install -e .
```

---
## 0: Frame correction
`curation_scripts/OCR_frame_mapping_BT_edit.py`

Run curation_scripts/OCR_frame_mapping_BT_edit.py by using:

```bash
python curation_scripts/OCR_frame_mapping_BT_edit.py PATH_TO_VIDEO_FOLDER
```
This creates the OCR files for the pipeline

# Details of the pipeline
Ideally, you should be able to run the pipeline by:
1. Set session info in `config/params.yaml`
2. Uncomment lines in `scripts/analyze_and_plot_FR_UA_NPRW.py` and run the entire pipeline

As long as you have the inputs:
1. Raw neural signals (NPRW, UA)
2. Metadata from handwritten notes
3. Mapping and geometry if available
4. params.yaml indicating location of data and other params
5. Impedances for both NPRW and UA

## 1. Align kinematics from two cameras
`batch_scripts/align_dlc_two_cams_to_br.py`

**Steps:**
1. Load OCR and DLC file for both cameras
2. Find corresponding BR `.ns5` files to extract rising edges in `camera_sync_ch` (corresponds to frames) Note: You can set this in `config/params.yaml`
3. Align both cameras to the BR frames
4. Output aligned .csv file

## 2. Neural data preprocessing (Intan / NPRW)
`batch_scripts/NPRW_Intan_analysis_threshold.py`

Preprocessing and spike sorting are handled in Python using [SpikeInterface](https://spikeinterface.readthedocs.io/)

**Steps:**
1. Load neural data and config (location to data, geometry and mapping)
2. Load geometry and mapping (.mat file)
3. Preprocess Intan (.rhs) data (high-pass filter, common local median reference default radius: 30, 150)  
4. Build bundles for data other then neural data (save as .npz file) (2 sync channels) (`intan_preproc.build_intan_bundle`) - TODO: Convert to NWB format
5. Extract stim data (save as .npz file)
6. Save per-session preprocessed data

Try plotting per channel + probe

7. **TODO** Artifact correction via PCA fitting
8. Concatenate sessions for sorting  
9. Run Kilosort4 (KS4) with Intan geometry and mapping
10. Export results in Phy format
11. **TODO** Optional now: SLAy
12. **TODO** Separate by condition
13. **TODO** Firing rate (FR) estimation using Gaussian filter?
14. **TODO** Align with BR using two sync pulses (one from BR side)

## 3. Align BR data to Intan
`batch_scripts/compute_br_to_intan_shifts.py`

## 4. Neural data preprocessing (BR / UA)
`batch_scripts/UA_Intan_analysis_threshold.py`

**Steps:**
1. Load neural data (.ns6) and config (location to data, geometry and mapping)
2. Load geometry and mapping (.xlsm file)
3. Preprocess UA data (high-pass filter)  
4. Build bundles for data other then neural data (save as .npz file) (2 sync digital channels in .ns5 and other .ns2 files) (`br_preproc.build_blackrock_bundle`) - TODO: Convert to NWB format
5. Save per-session preprocessed data
New pipeline using thresholding:
6. Using thresholding to detect spikes
7. **TODO** Use PCA to separate MUA within a cluster
8. FR estimation
12. Use as template to align Intan with BR using .ns5 sync pulses (two from BR side)
13. Use as template to align DLC kinematics file using the .ns5 sync pulses

Old pipeline envisioned:
6. Concatenate sessions for sorting
7. Run Mountainsort5 (MS5) with UA mapping (per-channel sorting)
8. Export results in Phy format
9. Optional now: SLAy
10. Separate by condition
11. FR estimation
12. Use as template to align Intan with BR using .ns5 sync pulses (two from BR side)
13. Use as template to align DLC kinematics file using the .ns5 sync pulses

## 5. Behavioral Analysis and Stim timing Processing
`batch_scripts/make_aligned_npz_from_shifts_with_behv.py`
TODO: Need to convert from MATLAB
TODO:
1. DLC labeling and annotations
2. Identify movement segments from DLC data
3. Load stimulation timing from Intan
4. Plot movement traces (how to align? based on velocity or based on stim timing?, try to plot baseline aligned by velocity first)
5. Calculate movement metrics (Previously: Endpoint error, Absolute endpoint error, Variance (in velocity) after stim, Variance (in velocity) after endpoint, Max speed, Avg speed, Endpoint oscillation, FFTPower after endpoint)
6. Calculate significance relative to baseline
7. Plot bargraphs

## 6. Create aligned baseline
`batch_scripts/create_aligned_combined_baseline.py`

## 7. Make baseline and peri-stim plots
`batch_scripts/NPRW_BEHV_UA_FR_plotting.py`



---

## Intermediate outputs:
Bundles:
1. Stim stream npz file from Intan for stim timing and channels
2. Auxiliary npz file from Intan for sync signals
3. Auxiliary npz file from BR for sync signals

Checkpoints:

4. Aligned kinematics
5. Preprocessed npy files in spikeinterface format (UA and NPRW)
6. Aligned kinematics, NPRW, and UA (spike locations and firing rate) data
7. TODO: Spike sorted data using KS4 in Phy format (Including mean waveforms, spike times)

Other:

8. Metadata for alignment of BR and Intan

## Outputs
1. Plots of kinematics (position and velocity) and neural data (Firing rate plot)
2. RSA to evaluate consistency of stim response

Use plot functions in `scripts` to plot raw traces with peaks labeled

See examples:

[Bert's plots for headturn](https://docs.google.com/presentation/d/1z6fLBiO8Wbell_FSsJK0Mcj66stKMJZmZtJu6tcY7FA/edit?slide=id.g35fb40ee04d_0_42#slide=id.g35fb40ee04d_0_42)
/
 [Nike's plots for reaching](https://docs.google.com/presentation/d/1IyVMR_M60ptEKUW1HeEVMPyRlBin64tVCVFx2P4NXo0/edit)

---

## Evaluation

## Contact
For questions, contact Bryan Tseng btseng2@jh.edu.

## Acknowledgements
Data collected by Robyn Mildren, and Bryan Tseng.
The artifact correction code for NPRW data was adapted from [this repository](https://github.com/RuihanQuan/Oculomotor_Pipeline) by Ruihan Quan.

## License
